urlscrape - 
	função scrape:
		vai receber uma url e devolver as informações dela

sites funcionando:
opovo - PERFEITAMENTE
tribuna do ceará - Perfeito
g1.globo.com - pega tudo, menos as imagens secundárias
		em algumas paginas so pega o titulo e subtitulo (FALTA CORPO DA NOTICIA E IMAGENS SECUNDARIAS)
diário do nordeste - Não pega a imagem, legenda e subtitulo ; pega o titulo e a notícia toda
veja.abril.com.br = não pega as imagens



blogpost - (tem a url e senha do site)
	função make_post:
	 	publica o post com as informações q ele recebe 

dicionario -
	(OK)vai ter um dicionario de categorias e (talvez tags), com uma função pra poder escrever incompleta as categorias e completar
		(fiz só pra categorias, mas se necessário só copiar pra tags)
	(OK)função pra converter uma data fácil de escrever para o formato do python 

publicarWP-
	função user_input:
	(OK)	recebe todos os dados necessários do usuário e chama os devidos scrpts para analiza-los

readtxturl - 
vai pegar várias urls em um bloco de texto(deixar fácil mudança para outro tipo de documento) e rodar publicarWP para cada url.


