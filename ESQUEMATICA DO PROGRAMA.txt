urlscrape - 
	Esse script vai pegar as url e analiza-las, será responsável por fazer o webScraping
	recebe: url do site pra analizar
	retorna: dicionário para ser publicado através do script blogpost
		
	usei a biblioteca Newspaper - é simples e funciona relativamente bem pra vários sites, porém precisa de ajustes pra alguns
	não sei se é possivel facilmente fazer esses ajustes
	
	como os sites estão se comportando com o código como ele está:
	
	opovo - PERFEITAMENTE
	g1.globo.com - pega tudo, menos as imagens secundárias
	tribuna do ceará - Todos os posts bem, porém com informações da publicação misturadas com o texto
	diário do nordeste - Não pega a imagem, legenda e subtitulo ; pega o titulo e a notícia toda
	veja.abril.com.br = não pega as imagens

	TO DO: !!!!!!!!
	fazer alguma maneira de reconhecer os sites base: ex (g1.globo.com) e agir diferente pra cada site, otimizando os resultados, tbm tem q saber como otimizar pros problemas desses sites


blogpost - recebe o dicionário de conteúdo a ser publicado e põe no site
	(tem a url e senha do site)

dicionario -
	serve pra organizar as categorias e tags e data das publicações
	vou por uma função com as categorias do site (talvez tags, n sei se é necessário)
	e já fiz uma função pra converter a data q o post vai ser publicado para o formato datetime.datetime
	

publicarWP-
	vai usar os outros scripts e publicar tudo

readtxturl - 
	essa vai ser a ultima função
	pra poder simplesmente colocar todos os links num documento de texto e postar todos
	vai pegar várias urls em um bloco de texto(deixar fácil mudança para outro tipo de documento) e rodar publicarWP para cada url.
	
	
